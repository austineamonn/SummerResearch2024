{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you are running this in a virtual environment! Otherwise you may cause problems to your main device. \n",
    "\n",
    "Look up how to create a virtual environment if you don't know how. Otherwise you can just run this in google colab. \n",
    "\n",
    "Then in your virtual environment run the following lines:\n",
    "\n",
    "***\n",
    "\n",
    "pip install jupyter\n",
    "\n",
    "pip install ipykernel\n",
    "\n",
    "python -m ipykernel install --user --name=myenv --display-name \"Python (myenv)\"\n",
    "\n",
    "pip install tensorflow\n",
    "\n",
    "pip install shap\n",
    "\n",
    "***\n",
    "\n",
    "The lines will install different packages and libraries that you need for this notebook. I may have forgotten some in which case you can likely just pip install \"name of package\" in the same format as above.\n",
    "\n",
    "Also, make sure to download all the files called here and every file in the 'data_files_for_data_construction' folder. Ideally you just download the whole github, but some of the CSV files are rather large.\n",
    "\n",
    "***\n",
    "\n",
    "Before we begin we have some standard python libraries to import that we will use throughout this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There was no existing dataset that contained the data needed for this project. Thus first we must generate a synthetic dataset. The dataset will be generated based on a variety of real data, mappings between datasets, and artificially generated lists. \n",
    "\n",
    "First we import the Data class which contains all the data needed to generate the synthetic dataset.\n",
    "\n",
    "Next we import the DataGenerator class for the CPU. Note that a version does exist that runs on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datafiles_for_data_construction.data import Data\n",
    "from data_generation.data_generation_CPU import DataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we instantiate the Data and DataGenerator classes. The Data class allows us to access all the data needed to generate the synthetic dataset and the DataGenerator class allows us to use the functions needed to generate the synthetic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data()\n",
    "data_generator = DataGenerator(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the data look like? Some of the data is a list of values. Some lists were generated synthetically, others were pulled from various sources. More information can be found in the README file. Here is a list of learning styles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Visual', 'Auditory', 'Read/Write', 'Kinesthetic']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.learning_style()[\"learning_style_list\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the data is a dictionary. Some dictionaries map different lists together while others map lists to demographic statistics on how common each item is. This dictionary maps the learning styles to the percentage of people that have said style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Visual': 27.27, 'Auditory': 23.56, 'Read/Write': 21.16, 'Kinesthetic': 28.01}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.learning_style()[\"learning_style\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the generate_synthetic_dataset function to create a dataset from all the data. This function has two inputs:\n",
    "- number of samples (an integer) which tell the function how many 'students' we want in our dataset\n",
    "- batch size (an integer) which tells the function how to split up the work to prevent overloading the computer.\n",
    "You can change the values if you want to generate more or less data. Be careful as higher values for number of samples will lead to a longer runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 100 # You can change these values if you want\n",
    "batch_size = 10 # Batch size should be about 1/10 of the number of samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we call the function. Use the time library to see how long the generator takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.887696743011475\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "synthetic_data = data_generator.generate_synthetic_dataset(num_samples, batch_size)\n",
    "end_time = time.time()\n",
    "runtime = end_time - start_time\n",
    "print(runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'generate_synthetic_dataset' outputs a pandas dataframe. Lets look at the top 5 elements of the dataframe. You can look back at the README file to get a better sense of what each column contains and how it was generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first name</th>\n",
       "      <th>last name</th>\n",
       "      <th>ethnoracial group</th>\n",
       "      <th>gender</th>\n",
       "      <th>international status</th>\n",
       "      <th>socioeconomic status</th>\n",
       "      <th>learning style</th>\n",
       "      <th>gpa</th>\n",
       "      <th>student semester</th>\n",
       "      <th>major</th>\n",
       "      <th>previous courses</th>\n",
       "      <th>course types</th>\n",
       "      <th>course subjects</th>\n",
       "      <th>subjects of interest</th>\n",
       "      <th>extracurricular activities</th>\n",
       "      <th>career aspirations</th>\n",
       "      <th>future topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Melton</td>\n",
       "      <td>Onley</td>\n",
       "      <td>European American or white</td>\n",
       "      <td>Female</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>Lower-middle income</td>\n",
       "      <td>[Auditory]</td>\n",
       "      <td>3.84</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>[CHBE Profession, Macroeconomic Principles, Sa...</td>\n",
       "      <td>[[Lecture-Discussion], [Discussion/Recitation,...</td>\n",
       "      <td>[SOCW, JS, STAT, EDUC, MILS, MUSC, CHBE, FSHN,...</td>\n",
       "      <td>[Engineering, Nuclear Engineering, Social Work...</td>\n",
       "      <td>[Women's Student Association, Electrical Engin...</td>\n",
       "      <td>[Engineer, Electrical and Electronic Engineer,...</td>\n",
       "      <td>[Environmental Engineering, Electrical Enginee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tuf</td>\n",
       "      <td>Hamet</td>\n",
       "      <td>Latino/a/x American</td>\n",
       "      <td>Female</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>Near poverty</td>\n",
       "      <td>[Auditory]</td>\n",
       "      <td>3.26</td>\n",
       "      <td>5</td>\n",
       "      <td>[Biological Engineering]</td>\n",
       "      <td>[Mythology of Greece and Rome, Undergraduate O...</td>\n",
       "      <td>[[Lecture-Discussion], [Lecture, Laboratory], ...</td>\n",
       "      <td>[AE, RST, AGCM, ECE, MCB, PS, MATH, ARTD, CLCV...</td>\n",
       "      <td>[Environmental Science, Education, Chemistry, ...</td>\n",
       "      <td>[Relay for Life, Biology Club, Engineering Soc...</td>\n",
       "      <td>[Industrial Engineer, including Health and Saf...</td>\n",
       "      <td>[Material Science, Biochemistry, Chemistry, Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Long</td>\n",
       "      <td>Bartelson</td>\n",
       "      <td>European American or white</td>\n",
       "      <td>Female</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>Near poverty</td>\n",
       "      <td>[Read/Write]</td>\n",
       "      <td>3.61</td>\n",
       "      <td>8</td>\n",
       "      <td>[General Social Sciences]</td>\n",
       "      <td>[Undergraduate Open Seminar, Leadership Labora...</td>\n",
       "      <td>[[Laboratory, Lecture-Discussion], [Lecture-Di...</td>\n",
       "      <td>[LING, RST, PHYS, ARTS, EDPR, STAT, ENVS, ARTF...</td>\n",
       "      <td>[Food Science and Human Nutrition, Art, Histor...</td>\n",
       "      <td>[European Student Association, Multicultural S...</td>\n",
       "      <td>[Musician, Singer, and Related Worker, Dietici...</td>\n",
       "      <td>[Anthropology, Cultural Studies, Political Sci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mattalynn</td>\n",
       "      <td>Hochstetter</td>\n",
       "      <td>African American or Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>Middle income</td>\n",
       "      <td>[Kinesthetic]</td>\n",
       "      <td>2.28</td>\n",
       "      <td>12</td>\n",
       "      <td>[Food Science]</td>\n",
       "      <td>[College Physics: Mech and Heat, Intro Asian A...</td>\n",
       "      <td>[[Lecture-Discussion], [Independent Study, Lec...</td>\n",
       "      <td>[JS, MCB, PHYS, HORT, CPSC, GEOL, MUS, CLE, MU...</td>\n",
       "      <td>[Environmental Science, Geology, Environmental...</td>\n",
       "      <td>[Environmental Science Club, Food Science Club...</td>\n",
       "      <td>[Dietician and Nutritionist, Agricultural and ...</td>\n",
       "      <td>[Food Science and Human Nutrition, Medicine, B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wale</td>\n",
       "      <td>Sherf</td>\n",
       "      <td>Multiracial</td>\n",
       "      <td>Female</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>Higher income</td>\n",
       "      <td>[Visual]</td>\n",
       "      <td>2.93</td>\n",
       "      <td>9</td>\n",
       "      <td>[International Relations, Miscellaneous Social...</td>\n",
       "      <td>[Intro to Academic Writing II, Beginning Germa...</td>\n",
       "      <td>[[Laboratory, Lecture, Online Lab, Online Lect...</td>\n",
       "      <td>[RST, AE, PHYS, HORT, GER, CPSC, JOUR, MUS, ST...</td>\n",
       "      <td>[History, Languages, International Relations, ...</td>\n",
       "      <td>[Sorority Council, Women's Student Association...</td>\n",
       "      <td>[Secretary and Administrative Assistant, Other...</td>\n",
       "      <td>[Educational Psychology, Education, Sociology,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  first name    last name           ethnoracial group  gender  \\\n",
       "0     Melton        Onley  European American or white  Female   \n",
       "1        Tuf        Hamet         Latino/a/x American  Female   \n",
       "2       Long    Bartelson  European American or white  Female   \n",
       "3  Mattalynn  Hochstetter   African American or Black    Male   \n",
       "4       Wale        Sherf                 Multiracial  Female   \n",
       "\n",
       "  international status socioeconomic status learning style   gpa  \\\n",
       "0             Domestic  Lower-middle income     [Auditory]  3.84   \n",
       "1             Domestic         Near poverty     [Auditory]  3.26   \n",
       "2             Domestic         Near poverty   [Read/Write]  3.61   \n",
       "3             Domestic        Middle income  [Kinesthetic]  2.28   \n",
       "4             Domestic        Higher income       [Visual]  2.93   \n",
       "\n",
       "   student semester                                              major  \\\n",
       "0                 4                                                 []   \n",
       "1                 5                           [Biological Engineering]   \n",
       "2                 8                          [General Social Sciences]   \n",
       "3                12                                     [Food Science]   \n",
       "4                 9  [International Relations, Miscellaneous Social...   \n",
       "\n",
       "                                    previous courses  \\\n",
       "0  [CHBE Profession, Macroeconomic Principles, Sa...   \n",
       "1  [Mythology of Greece and Rome, Undergraduate O...   \n",
       "2  [Undergraduate Open Seminar, Leadership Labora...   \n",
       "3  [College Physics: Mech and Heat, Intro Asian A...   \n",
       "4  [Intro to Academic Writing II, Beginning Germa...   \n",
       "\n",
       "                                        course types  \\\n",
       "0  [[Lecture-Discussion], [Discussion/Recitation,...   \n",
       "1  [[Lecture-Discussion], [Lecture, Laboratory], ...   \n",
       "2  [[Laboratory, Lecture-Discussion], [Lecture-Di...   \n",
       "3  [[Lecture-Discussion], [Independent Study, Lec...   \n",
       "4  [[Laboratory, Lecture, Online Lab, Online Lect...   \n",
       "\n",
       "                                     course subjects  \\\n",
       "0  [SOCW, JS, STAT, EDUC, MILS, MUSC, CHBE, FSHN,...   \n",
       "1  [AE, RST, AGCM, ECE, MCB, PS, MATH, ARTD, CLCV...   \n",
       "2  [LING, RST, PHYS, ARTS, EDPR, STAT, ENVS, ARTF...   \n",
       "3  [JS, MCB, PHYS, HORT, CPSC, GEOL, MUS, CLE, MU...   \n",
       "4  [RST, AE, PHYS, HORT, GER, CPSC, JOUR, MUS, ST...   \n",
       "\n",
       "                                subjects of interest  \\\n",
       "0  [Engineering, Nuclear Engineering, Social Work...   \n",
       "1  [Environmental Science, Education, Chemistry, ...   \n",
       "2  [Food Science and Human Nutrition, Art, Histor...   \n",
       "3  [Environmental Science, Geology, Environmental...   \n",
       "4  [History, Languages, International Relations, ...   \n",
       "\n",
       "                          extracurricular activities  \\\n",
       "0  [Women's Student Association, Electrical Engin...   \n",
       "1  [Relay for Life, Biology Club, Engineering Soc...   \n",
       "2  [European Student Association, Multicultural S...   \n",
       "3  [Environmental Science Club, Food Science Club...   \n",
       "4  [Sorority Council, Women's Student Association...   \n",
       "\n",
       "                                  career aspirations  \\\n",
       "0  [Engineer, Electrical and Electronic Engineer,...   \n",
       "1  [Industrial Engineer, including Health and Saf...   \n",
       "2  [Musician, Singer, and Related Worker, Dietici...   \n",
       "3  [Dietician and Nutritionist, Agricultural and ...   \n",
       "4  [Secretary and Administrative Assistant, Other...   \n",
       "\n",
       "                                       future topics  \n",
       "0  [Environmental Engineering, Electrical Enginee...  \n",
       "1  [Material Science, Biochemistry, Chemistry, Ch...  \n",
       "2  [Anthropology, Cultural Studies, Political Sci...  \n",
       "3  [Food Science and Human Nutrition, Medicine, B...  \n",
       "4  [Educational Psychology, Education, Sociology,...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_data.head(n=5) # Change n to larger numbers to see more rows of the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we have columns that are lists and columns that are strings. Machine learning models need the input data to be numerical. Thus some data preprocessing is required.\n",
    "\n",
    "We import the Preprocessing class to do the preprocessing work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preprocessing.preprocessing import PreProcessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside the Preprocessing class there are two functions that do the main preprocessing work:\n",
    "- 'stringlist_to_binarylist': converts lists of strings into a binary list\n",
    "- 'string_list_to_numberedlist': converts lits of strings into a numbered list.\n",
    "\n",
    "Imagine the full options available are ['alice', 'bob', 'charlie']\n",
    "Thus for the entry ['alice', 'charlie'] we get:\n",
    "[1,0,1] for 'stringlist_to_binarylist'\n",
    "[0,2] for 'string_list_to_numberedlist'\n",
    "\n",
    "When we instantiate the class and call the 'preprocess_dataset' function both of the above functions will be called on certain columns. 'stringlist_to_binarylist' is called on 'learning styles' and 'string_list_to_numberedlist' is called on all the other lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15332794189453125\n"
     ]
    }
   ],
   "source": [
    "preprocessor = PreProcessing(data)\n",
    "start_time = time.time()\n",
    "preprocessed_data = preprocessor.preprocess_dataset(synthetic_data)\n",
    "end_time = time.time()\n",
    "runtime = end_time - start_time\n",
    "print(runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'preprocess_dataset' outputs a pandas dataframe. Lets look at the top 5 elements of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning style</th>\n",
       "      <th>gpa</th>\n",
       "      <th>student semester</th>\n",
       "      <th>major</th>\n",
       "      <th>previous courses</th>\n",
       "      <th>course types</th>\n",
       "      <th>course subjects</th>\n",
       "      <th>subjects of interest</th>\n",
       "      <th>extracurricular activities</th>\n",
       "      <th>career aspirations</th>\n",
       "      <th>future topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 1, 0, 0]</td>\n",
       "      <td>3.84</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>[482, 2122, 2764, 298, 714, 1832, 3461, 3191, ...</td>\n",
       "      <td>[0, 5, 10, 1, 2, 3, 6, 20]</td>\n",
       "      <td>[156, 113, 160, 67, 134, 138, 45, 86, 61, 206,...</td>\n",
       "      <td>[18, 93, 117, 67, 108, 14, 8]</td>\n",
       "      <td>[11, 28, 62, 48, 19]</td>\n",
       "      <td>[51, 49, 105, 87, 146, 27, 70, 85]</td>\n",
       "      <td>[55, 51, 145, 123, 50]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 1, 0, 0]</td>\n",
       "      <td>3.26</td>\n",
       "      <td>5</td>\n",
       "      <td>[17]</td>\n",
       "      <td>[2280, 3338, 1313, 1312, 3450, 1312, 1692, 126...</td>\n",
       "      <td>[0, 4, 5, 10, 1, 2, 3, 17]</td>\n",
       "      <td>[6, 154, 10, 64, 129, 228, 127, 20, 52, 118, 7...</td>\n",
       "      <td>[15, 22, 3, 53]</td>\n",
       "      <td>[149, 82, 62, 48, 23, 212, 5]</td>\n",
       "      <td>[70, 27, 23, 85, 87, 82, 52, 51, 105, 49, 24]</td>\n",
       "      <td>[108, 21, 30, 29, 128]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "      <td>3.61</td>\n",
       "      <td>8</td>\n",
       "      <td>[74]</td>\n",
       "      <td>[3338, 2041, 1911, 556, 816, 1346, 3461, 2220,...</td>\n",
       "      <td>[9, 0, 4, 5, 10, 1, 2, 3, 11, 6, 20, 17]</td>\n",
       "      <td>[124, 154, 147, 25, 66, 160, 74, 22, 138, 30, ...</td>\n",
       "      <td>[67, 7, 4, 72, 9]</td>\n",
       "      <td>[22, 34, 107, 71, 90]</td>\n",
       "      <td>[94, 45, 130, 50, 112, 138, 114, 62, 101, 26]</td>\n",
       "      <td>[9, 37, 132, 191, 84]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 0, 0, 1]</td>\n",
       "      <td>2.28</td>\n",
       "      <td>12</td>\n",
       "      <td>[66]</td>\n",
       "      <td>[607, 1732, 606, 3338, 1077, 2443, 606, 482, 2...</td>\n",
       "      <td>[9, 0, 4, 13, 5, 10, 1, 2, 3, 7, 6, 20, 14]</td>\n",
       "      <td>[113, 129, 147, 102, 55, 88, 137, 53, 138, 216...</td>\n",
       "      <td>[15, 16, 63, 96, 67, 0, 53, 128, 18]</td>\n",
       "      <td>[79, 97, 81, 55]</td>\n",
       "      <td>[45, 4, 35, 79, 65, 108, 121, 12, 53, 54, 100]</td>\n",
       "      <td>[69, 114, 21, 134, 124]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 0, 0, 0]</td>\n",
       "      <td>2.93</td>\n",
       "      <td>9</td>\n",
       "      <td>[94, 125]</td>\n",
       "      <td>[1754, 395, 1310, 1346, 816, 1675, 1528, 270, ...</td>\n",
       "      <td>[0, 4, 5, 10, 1, 2, 3, 11, 6, 20, 19]</td>\n",
       "      <td>[154, 6, 147, 102, 89, 55, 112, 137, 160, 138,...</td>\n",
       "      <td>[4, 24, 129, 12, 72]</td>\n",
       "      <td>[9, 11, 107, 110, 60, 71, 27, 98, 169, 84, 43]</td>\n",
       "      <td>[131, 101, 26, 61, 75, 24, 40, 20, 107, 73, 14...</td>\n",
       "      <td>[49, 48, 148, 191, 65]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  learning style   gpa  student semester      major  \\\n",
       "0   [0, 1, 0, 0]  3.84                 4         []   \n",
       "1   [0, 1, 0, 0]  3.26                 5       [17]   \n",
       "2   [0, 0, 1, 0]  3.61                 8       [74]   \n",
       "3   [0, 0, 0, 1]  2.28                12       [66]   \n",
       "4   [1, 0, 0, 0]  2.93                 9  [94, 125]   \n",
       "\n",
       "                                    previous courses  \\\n",
       "0  [482, 2122, 2764, 298, 714, 1832, 3461, 3191, ...   \n",
       "1  [2280, 3338, 1313, 1312, 3450, 1312, 1692, 126...   \n",
       "2  [3338, 2041, 1911, 556, 816, 1346, 3461, 2220,...   \n",
       "3  [607, 1732, 606, 3338, 1077, 2443, 606, 482, 2...   \n",
       "4  [1754, 395, 1310, 1346, 816, 1675, 1528, 270, ...   \n",
       "\n",
       "                                  course types  \\\n",
       "0                   [0, 5, 10, 1, 2, 3, 6, 20]   \n",
       "1                   [0, 4, 5, 10, 1, 2, 3, 17]   \n",
       "2     [9, 0, 4, 5, 10, 1, 2, 3, 11, 6, 20, 17]   \n",
       "3  [9, 0, 4, 13, 5, 10, 1, 2, 3, 7, 6, 20, 14]   \n",
       "4        [0, 4, 5, 10, 1, 2, 3, 11, 6, 20, 19]   \n",
       "\n",
       "                                     course subjects  \\\n",
       "0  [156, 113, 160, 67, 134, 138, 45, 86, 61, 206,...   \n",
       "1  [6, 154, 10, 64, 129, 228, 127, 20, 52, 118, 7...   \n",
       "2  [124, 154, 147, 25, 66, 160, 74, 22, 138, 30, ...   \n",
       "3  [113, 129, 147, 102, 55, 88, 137, 53, 138, 216...   \n",
       "4  [154, 6, 147, 102, 89, 55, 112, 137, 160, 138,...   \n",
       "\n",
       "                   subjects of interest  \\\n",
       "0         [18, 93, 117, 67, 108, 14, 8]   \n",
       "1                       [15, 22, 3, 53]   \n",
       "2                     [67, 7, 4, 72, 9]   \n",
       "3  [15, 16, 63, 96, 67, 0, 53, 128, 18]   \n",
       "4                  [4, 24, 129, 12, 72]   \n",
       "\n",
       "                       extracurricular activities  \\\n",
       "0                            [11, 28, 62, 48, 19]   \n",
       "1                   [149, 82, 62, 48, 23, 212, 5]   \n",
       "2                           [22, 34, 107, 71, 90]   \n",
       "3                                [79, 97, 81, 55]   \n",
       "4  [9, 11, 107, 110, 60, 71, 27, 98, 169, 84, 43]   \n",
       "\n",
       "                                  career aspirations            future topics  \n",
       "0                 [51, 49, 105, 87, 146, 27, 70, 85]   [55, 51, 145, 123, 50]  \n",
       "1      [70, 27, 23, 85, 87, 82, 52, 51, 105, 49, 24]   [108, 21, 30, 29, 128]  \n",
       "2      [94, 45, 130, 50, 112, 138, 114, 62, 101, 26]    [9, 37, 132, 191, 84]  \n",
       "3     [45, 4, 35, 79, 65, 108, 121, 12, 53, 54, 100]  [69, 114, 21, 134, 124]  \n",
       "4  [131, 101, 26, 61, 75, 24, 40, 20, 107, 73, 14...   [49, 48, 148, 191, 65]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_data.head(n=5) # Change n to larger numbers to see more rows of the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data has been preprocessed we must privatize the data to keep it safe.\n",
    "\n",
    "We import the Privatizer class to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_privatization.privatization import Privatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a variety of privatization methods you can try:\n",
    "- Basic Differential Privacy (laplace noise addition)\n",
    "- Uniform Noise Differential Privacy (uniform noise addition)\n",
    "- Shuffling\n",
    "Both Differential Privacy types can be done with or without list lengthening. This means the list columns like 'previous courses' could be lengthened according to the noise addition function. More details can be found in the README file. Let's try basic differential privacy with list lengthening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "privatization_type = 'basic differential privacy'\n",
    "# Other 'privatization_type' options: 'uniform', 'shuffle', 'full shuffle' (full shuffle shuffles all of the rows)\n",
    "privatizer = Privatizer(data, style=privatization_type, list_length=True)\n",
    "# Can set 'list_length' to false if you don't want to allow the list sizes to change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we call 'privatize_dataset'. Use the time library to see how long the privatizer takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.020509958267211914\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "privatized_data = privatizer.privatize_dataset(preprocessed_data)\n",
    "end_time = time.time()\n",
    "runtime = end_time - start_time\n",
    "print(runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'preprocess_dataset' outputs a pandas dataframe. Lets look at the top 5 elements of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning style</th>\n",
       "      <th>gpa</th>\n",
       "      <th>student semester</th>\n",
       "      <th>major</th>\n",
       "      <th>previous courses</th>\n",
       "      <th>course types</th>\n",
       "      <th>course subjects</th>\n",
       "      <th>subjects of interest</th>\n",
       "      <th>extracurricular activities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "      <td>3.05</td>\n",
       "      <td>12</td>\n",
       "      <td>[]</td>\n",
       "      <td>[425, 1708, 1356, 469, 832, 1144, 3381, 2390, ...</td>\n",
       "      <td>[10, 3, 8, 7, 9, 9, 13, 13, 17, 15, 5, 2, 14, ...</td>\n",
       "      <td>[194, 26, 158, 47, 121, 164, 65]</td>\n",
       "      <td>[5, 123, 63, 109, 115, 102, 108, 101, 94]</td>\n",
       "      <td>[262, 31, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 1, 1, 0]</td>\n",
       "      <td>3.28</td>\n",
       "      <td>5</td>\n",
       "      <td>[]</td>\n",
       "      <td>[2392, 1787, 86, 3386, 2891, 1637, 2540, 564, ...</td>\n",
       "      <td>[13, 17, 4, 7, 2, 4, 13, 9, 13, 17, 0, 3, 6, 1...</td>\n",
       "      <td>[137, 91, 141, 117, 146, 158, 172, 7, 90, 3, 1...</td>\n",
       "      <td>[24, 129, 101, 117, 117, 34, 50, 120, 84, 73, ...</td>\n",
       "      <td>[138, 230, 218, 265, 277, 246, 88, 73, 151, 18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 0, 0, 1]</td>\n",
       "      <td>3.47</td>\n",
       "      <td>0</td>\n",
       "      <td>[121, 77]</td>\n",
       "      <td>[321, 667, 402, 2561, 620, 1930, 2771, 2990, 5...</td>\n",
       "      <td>[1, 8, 6, 21, 18, 1, 21, 10, 7, 3, 19, 4, 18, ...</td>\n",
       "      <td>[30, 212, 156, 17, 67, 54, 0, 196, 122, 94, 52...</td>\n",
       "      <td>[29, 42, 9, 73, 128, 72, 128, 65, 25, 28, 63, ...</td>\n",
       "      <td>[295, 254, 289, 22, 104, 97, 151, 231, 284, 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 1, 1, 1]</td>\n",
       "      <td>3.73</td>\n",
       "      <td>11</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1391, 2944, 1, 2850, 1837, 947, 2758, 2570, 2...</td>\n",
       "      <td>[12, 19, 8]</td>\n",
       "      <td>[155, 2, 151, 22, 181, 234, 11, 114, 190, 94]</td>\n",
       "      <td>[99, 92, 11, 11, 136, 85, 35, 83, 51, 90, 117,...</td>\n",
       "      <td>[251, 303, 185, 258, 195, 29, 179, 85, 5, 255,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 0, 1, 1]</td>\n",
       "      <td>3.73</td>\n",
       "      <td>7</td>\n",
       "      <td>[]</td>\n",
       "      <td>[2251, 241, 425, 1697, 482, 2450, 2029, 1599, ...</td>\n",
       "      <td>[20, 15, 19, 2, 9, 13, 20, 10, 9, 13, 15, 13, ...</td>\n",
       "      <td>[32, 109, 55, 123, 176, 7, 5, 9, 4, 231, 45, 1...</td>\n",
       "      <td>[40, 101, 8, 132, 102, 35, 5]</td>\n",
       "      <td>[122, 239, 80, 37, 28, 239, 86, 147, 161, 198,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  learning style   gpa  student semester      major  \\\n",
       "0   [0, 0, 1, 0]  3.05                12         []   \n",
       "1   [1, 1, 1, 0]  3.28                 5         []   \n",
       "2   [0, 0, 0, 1]  3.47                 0  [121, 77]   \n",
       "3   [0, 1, 1, 1]  3.73                11         []   \n",
       "4   [1, 0, 1, 1]  3.73                 7         []   \n",
       "\n",
       "                                    previous courses  \\\n",
       "0  [425, 1708, 1356, 469, 832, 1144, 3381, 2390, ...   \n",
       "1  [2392, 1787, 86, 3386, 2891, 1637, 2540, 564, ...   \n",
       "2  [321, 667, 402, 2561, 620, 1930, 2771, 2990, 5...   \n",
       "3  [1391, 2944, 1, 2850, 1837, 947, 2758, 2570, 2...   \n",
       "4  [2251, 241, 425, 1697, 482, 2450, 2029, 1599, ...   \n",
       "\n",
       "                                        course types  \\\n",
       "0  [10, 3, 8, 7, 9, 9, 13, 13, 17, 15, 5, 2, 14, ...   \n",
       "1  [13, 17, 4, 7, 2, 4, 13, 9, 13, 17, 0, 3, 6, 1...   \n",
       "2  [1, 8, 6, 21, 18, 1, 21, 10, 7, 3, 19, 4, 18, ...   \n",
       "3                                        [12, 19, 8]   \n",
       "4  [20, 15, 19, 2, 9, 13, 20, 10, 9, 13, 15, 13, ...   \n",
       "\n",
       "                                     course subjects  \\\n",
       "0                   [194, 26, 158, 47, 121, 164, 65]   \n",
       "1  [137, 91, 141, 117, 146, 158, 172, 7, 90, 3, 1...   \n",
       "2  [30, 212, 156, 17, 67, 54, 0, 196, 122, 94, 52...   \n",
       "3      [155, 2, 151, 22, 181, 234, 11, 114, 190, 94]   \n",
       "4  [32, 109, 55, 123, 176, 7, 5, 9, 4, 231, 45, 1...   \n",
       "\n",
       "                                subjects of interest  \\\n",
       "0          [5, 123, 63, 109, 115, 102, 108, 101, 94]   \n",
       "1  [24, 129, 101, 117, 117, 34, 50, 120, 84, 73, ...   \n",
       "2  [29, 42, 9, 73, 128, 72, 128, 65, 25, 28, 63, ...   \n",
       "3  [99, 92, 11, 11, 136, 85, 35, 83, 51, 90, 117,...   \n",
       "4                      [40, 101, 8, 132, 102, 35, 5]   \n",
       "\n",
       "                          extracurricular activities  \n",
       "0                                      [262, 31, 25]  \n",
       "1  [138, 230, 218, 265, 277, 246, 88, 73, 151, 18...  \n",
       "2  [295, 254, 289, 22, 104, 97, 151, 231, 284, 21...  \n",
       "3  [251, 303, 185, 258, 195, 29, 179, 85, 5, 255,...  \n",
       "4  [122, 239, 80, 37, 28, 239, 86, 147, 161, 198,...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "privatized_data.head(n=5) # Change n to larger numbers to see more rows of the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have the problem of long lists. The 'previous courses list' can be over 30 elements long! Thus we call a new function from the Preprocessor class, 'create_RNN_models'. Three different recurrent neural network models are used to reduce the dimension of each list to 1 element. The three networks are: Simple, GRU (Gated Recurrent Units), and LSTM (Long Term Short Memory).\n",
    "\n",
    "Since 'create_RNN_models' takes in a dataframe, there is no need to create a new instance of the Preprocessor class. Thus we should call:\n",
    "- 'privatized_data': reduce dimensionality\n",
    "- 'preprocessed_data': give a null for comparison at the end\n",
    "- 'preprocessed_data' with 'utility=True': reduce dimensionality of the utility columns\n",
    "\n",
    "Let's also calculate and compare the runtimes.\n",
    "\n",
    "Let us just use the simple RNN dimensionality reduction. Though this can be switch by changing 'simple' to False and a different method to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-13 15:45:35.840766: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2024-07-13 15:45:35.840798: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2024-07-13 15:45:35.840805: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2024-07-13 15:45:35.841177: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-07-13 15:45:35.841194: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-13 15:45:36.634402: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - loss: 0.3076\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.1170\n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.1015\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0834\n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0954\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0808\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0724\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0764\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0832\n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0772\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.2778\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0999\n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.1020\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0987\n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0815\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0684\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0672\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0598\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0543\n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0539\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - loss: 0.1950\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - loss: 0.0953\n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - loss: 0.0689\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - loss: 0.0392\n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - loss: 0.0408\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - loss: 0.0265\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - loss: 0.0254\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - loss: 0.0193\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - loss: 0.0166\n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - loss: 0.0136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-13 15:46:54,488 - tensorflow - WARNING - 5 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x319270cc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 137ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-13 15:46:54,972 - tensorflow - WARNING - 6 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x319270cc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 162ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 290ms/step - loss: 0.3533\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 263ms/step - loss: 0.1042\n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 262ms/step - loss: 0.0774\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 264ms/step - loss: 0.0715\n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 262ms/step - loss: 0.0604\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 267ms/step - loss: 0.0485\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 309ms/step - loss: 0.0470\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 266ms/step - loss: 0.0411\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 261ms/step - loss: 0.0374\n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 269ms/step - loss: 0.0287\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - loss: 0.5319\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - loss: 0.1114\n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0822\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0626\n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0541\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0469\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0445\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0429\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0380\n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0363\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5s/step - loss: 0.1963\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5s/step - loss: 0.0760\n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5s/step - loss: 0.0702\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5s/step - loss: 0.0618\n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5s/step - loss: 0.0657\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5s/step - loss: 0.0616\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5s/step - loss: 0.0607\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5s/step - loss: 0.0648\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5s/step - loss: 0.0531\n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5s/step - loss: 0.0496\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 365ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 756ms/step - loss: 0.1894\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 726ms/step - loss: 0.0694\n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 786ms/step - loss: 0.0545\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 743ms/step - loss: 0.0475\n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 892ms/step - loss: 0.0315\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 856ms/step - loss: 0.0249\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 733ms/step - loss: 0.0229\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 765ms/step - loss: 0.0182\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 745ms/step - loss: 0.0155\n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 798ms/step - loss: 0.0135\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.2927\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.1018\n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.1099\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0904\n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.1025\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.1088\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0948\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.2801\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1415\n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1013\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0968\n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0854\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0648\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0547\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0438\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0428\n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0354\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2s/step - loss: 0.3097\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - loss: 0.1078\n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - loss: 0.0587\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - loss: 0.0728\n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - loss: 0.0601\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - loss: 0.0529\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3s/step - loss: 0.0447\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3s/step - loss: 0.0405\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - loss: 0.0270\n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2s/step - loss: 0.0186\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 167ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.2001\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 167ms/step - loss: 0.1315\n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 163ms/step - loss: 0.0970\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 371ms/step - loss: 0.0826\n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 359ms/step - loss: 0.0681\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 273ms/step - loss: 0.0707\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 198ms/step - loss: 0.0618\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 181ms/step - loss: 0.0596\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 173ms/step - loss: 0.0568\n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 214ms/step - loss: 0.0604\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2s/step - loss: 0.3457\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - loss: 0.0764\n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - loss: 0.0913\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - loss: 0.0513\n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0541\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - loss: 0.0389\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - loss: 0.0384\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - loss: 0.0355\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - loss: 0.0241\n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - loss: 0.0232\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 841ms/step - loss: 0.3022\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 809ms/step - loss: 0.0929\n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 734ms/step - loss: 0.0860\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 730ms/step - loss: 0.0774\n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 731ms/step - loss: 0.0704\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 757ms/step - loss: 0.0651\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 850ms/step - loss: 0.0704\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 907ms/step - loss: 0.0652\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 969ms/step - loss: 0.0576\n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - loss: 0.0669\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 233ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - loss: 0.3202\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 472ms/step - loss: 0.1261\n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 546ms/step - loss: 0.0738\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 435ms/step - loss: 0.0658\n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 524ms/step - loss: 0.0501\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 562ms/step - loss: 0.0469\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 576ms/step - loss: 0.0365\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 545ms/step - loss: 0.0317\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 474ms/step - loss: 0.0259\n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 607ms/step - loss: 0.0208\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 478ms/step - loss: 0.2346\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 405ms/step - loss: 0.0727\n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 386ms/step - loss: 0.0649\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 339ms/step - loss: 0.0385\n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 345ms/step - loss: 0.0358\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 473ms/step - loss: 0.0253\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 506ms/step - loss: 0.0205\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 396ms/step - loss: 0.0145\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 392ms/step - loss: 0.0134\n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 701ms/step - loss: 0.0113\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 183ms/step - loss: 0.3308\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.1817\n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0817\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0586\n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0658\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0298\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0240\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0232\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0210\n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0101\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step\n",
      "Privatized data runtime: 383.9635717868805\n",
      "Nonprivatized data runtime: 235.4301187992096\n",
      "Utility columns runtime: 26.465418100357056\n"
     ]
    }
   ],
   "source": [
    "# Only let one of simple, LSTM, and GRU be equal to true.\n",
    "\n",
    "start_time = time.time()\n",
    "privatized_data_reduced = preprocessor.create_RNN_models(privatized_data, simple=True, LSTM=False, GRU=False)\n",
    "end_time = time.time()\n",
    "runtime_pd = end_time - start_time\n",
    "\n",
    "start_time = time.time()\n",
    "nonprivatized_data_reduced = preprocessor.create_RNN_models(preprocessed_data, simple=True, LSTM=False, GRU=False)\n",
    "end_time = time.time()\n",
    "runtime_npd = end_time - start_time\n",
    "\n",
    "start_time = time.time()\n",
    "utility_cols_reduced = preprocessor.create_RNN_models(preprocessed_data, utility=True, simple=True, LSTM=False, GRU=False)\n",
    "end_time = time.time()\n",
    "runtime_uc = end_time - start_time\n",
    "\n",
    "print(f'Privatized data runtime: {runtime_pd}')\n",
    "print(f'Nonprivatized data runtime: {runtime_npd}')\n",
    "print(f'Utility columns runtime: {runtime_uc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this code can be run to produce many dataframes the output is a list. We only made one dataframe so let's just take the first element from the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "privatized_data_reduced = privatized_data_reduced[0]\n",
    "\n",
    "nonprivatized_data_reduced = nonprivatized_data_reduced[0]\n",
    "\n",
    "utility_cols_reduced = utility_cols_reduced[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'create_RNN_models' outputs a pandas dataframe. Lets look at the top 5 elements for each of the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  learning style   gpa  student semester         major previous courses  \\\n",
      "0   [0.51466924]  3.05                12  [0.57751447]      [0.5620219]   \n",
      "1    [0.4353882]  3.28                 5  [0.57751447]      [0.7609531]   \n",
      "2    [0.5776786]  3.47                 0  [0.53115463]    [0.017651517]   \n",
      "3   [0.53910905]  3.73                11  [0.57751447]     [0.28403044]   \n",
      "4    [0.5401469]  3.73                 7  [0.57751447]      [0.7765268]   \n",
      "\n",
      "   course types course subjects subjects of interest  \\\n",
      "0   [0.1339442]     [0.5637837]         [0.51197636]   \n",
      "1  [0.56017077]     [0.4102107]         [0.37886214]   \n",
      "2    [0.631463]     [0.5462269]         [0.51299524]   \n",
      "3    [0.589439]      [0.642634]          [0.8003199]   \n",
      "4   [0.6601572]    [0.27176663]         [0.50578284]   \n",
      "\n",
      "  extracurricular activities  \n",
      "0               [0.58821774]  \n",
      "1                [0.4986311]  \n",
      "2               [0.17438826]  \n",
      "3                [0.6991976]  \n",
      "4                [0.5451047]  \n",
      "  learning style   gpa  student semester         major previous courses  \\\n",
      "0    [0.5376462]  3.84                 4  [0.41955322]     [0.88638633]   \n",
      "1    [0.5376462]  3.26                 5  [0.08774281]     [0.55915296]   \n",
      "2    [0.4410508]  3.61                 8  [0.70278543]     [0.74052924]   \n",
      "3    [0.5345103]  2.28                12  [0.13271166]     [0.40154916]   \n",
      "4    [0.5352876]  2.93                 9  [0.22174129]      [0.8778979]   \n",
      "\n",
      "   course types course subjects subjects of interest  \\\n",
      "0  [0.34658754]    [0.65389526]         [0.51253295]   \n",
      "1  [0.42354318]    [0.46442282]          [0.4339276]   \n",
      "2   [0.3093754]   [0.091108434]         [0.32733145]   \n",
      "3  [0.65194726]     [0.4375385]           [0.514679]   \n",
      "4  [0.44041365]    [0.67201746]         [0.36228055]   \n",
      "\n",
      "  extracurricular activities  \\\n",
      "0                [0.7454947]   \n",
      "1               [0.49763027]   \n",
      "2               [0.39969215]   \n",
      "3               [0.38828245]   \n",
      "4               [0.40747032]   \n",
      "\n",
      "                                  career aspirations            future topics  \n",
      "0                 [51, 49, 105, 87, 146, 27, 70, 85]   [55, 51, 145, 123, 50]  \n",
      "1      [70, 27, 23, 85, 87, 82, 52, 51, 105, 49, 24]   [108, 21, 30, 29, 128]  \n",
      "2      [94, 45, 130, 50, 112, 138, 114, 62, 101, 26]    [9, 37, 132, 191, 84]  \n",
      "3     [45, 4, 35, 79, 65, 108, 121, 12, 53, 54, 100]  [69, 114, 21, 134, 124]  \n",
      "4  [131, 101, 26, 61, 75, 24, 40, 20, 107, 73, 14...   [49, 48, 148, 191, 65]  \n",
      "  learning style   gpa  student semester      major  \\\n",
      "0   [0, 1, 0, 0]  3.84                 4         []   \n",
      "1   [0, 1, 0, 0]  3.26                 5       [17]   \n",
      "2   [0, 0, 1, 0]  3.61                 8       [74]   \n",
      "3   [0, 0, 0, 1]  2.28                12       [66]   \n",
      "4   [1, 0, 0, 0]  2.93                 9  [94, 125]   \n",
      "\n",
      "                                    previous courses  \\\n",
      "0  [482, 2122, 2764, 298, 714, 1832, 3461, 3191, ...   \n",
      "1  [2280, 3338, 1313, 1312, 3450, 1312, 1692, 126...   \n",
      "2  [3338, 2041, 1911, 556, 816, 1346, 3461, 2220,...   \n",
      "3  [607, 1732, 606, 3338, 1077, 2443, 606, 482, 2...   \n",
      "4  [1754, 395, 1310, 1346, 816, 1675, 1528, 270, ...   \n",
      "\n",
      "                                  course types  \\\n",
      "0                   [0, 5, 10, 1, 2, 3, 6, 20]   \n",
      "1                   [0, 4, 5, 10, 1, 2, 3, 17]   \n",
      "2     [9, 0, 4, 5, 10, 1, 2, 3, 11, 6, 20, 17]   \n",
      "3  [9, 0, 4, 13, 5, 10, 1, 2, 3, 7, 6, 20, 14]   \n",
      "4        [0, 4, 5, 10, 1, 2, 3, 11, 6, 20, 19]   \n",
      "\n",
      "                                     course subjects  \\\n",
      "0  [156, 113, 160, 67, 134, 138, 45, 86, 61, 206,...   \n",
      "1  [6, 154, 10, 64, 129, 228, 127, 20, 52, 118, 7...   \n",
      "2  [124, 154, 147, 25, 66, 160, 74, 22, 138, 30, ...   \n",
      "3  [113, 129, 147, 102, 55, 88, 137, 53, 138, 216...   \n",
      "4  [154, 6, 147, 102, 89, 55, 112, 137, 160, 138,...   \n",
      "\n",
      "                   subjects of interest  \\\n",
      "0         [18, 93, 117, 67, 108, 14, 8]   \n",
      "1                       [15, 22, 3, 53]   \n",
      "2                     [67, 7, 4, 72, 9]   \n",
      "3  [15, 16, 63, 96, 67, 0, 53, 128, 18]   \n",
      "4                  [4, 24, 129, 12, 72]   \n",
      "\n",
      "                       extracurricular activities career aspirations  \\\n",
      "0                            [11, 28, 62, 48, 19]        [0.6401636]   \n",
      "1                   [149, 82, 62, 48, 23, 212, 5]        [0.3287324]   \n",
      "2                           [22, 34, 107, 71, 90]       [0.18268186]   \n",
      "3                                [79, 97, 81, 55]       [0.17517279]   \n",
      "4  [9, 11, 107, 110, 60, 71, 27, 98, 169, 84, 43]       [0.36177412]   \n",
      "\n",
      "  future topics  \n",
      "0  [0.24151744]  \n",
      "1   [0.7343037]  \n",
      "2  [0.54844093]  \n",
      "3   [0.8659274]  \n",
      "4  [0.56258154]  \n"
     ]
    }
   ],
   "source": [
    "print(privatized_data_reduced.head(n=5))\n",
    "print(nonprivatized_data_reduced.head(n=5))\n",
    "print(utility_cols_reduced.head(n=5))\n",
    "# Change n to larger numbers to see more rows of the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to preprocess the private columns so that machine learning models can train on them. To do this we import the PrivateColumns from the 'preprocessing_private_columns' file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preprocessing.processing_private_columns import PrivateColumns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can instantiate the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "private_columns_data = PrivateColumns(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the privacy columns from the nonprivatized dataset as we only need them once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "privacy_columns = private_columns_data.get_private_cols(synthetic_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use pandas to combine back together the feature columns, the private columns, and the utility columns. We do this for both the privatized and nonprivatized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "privatized_combined = pd.concat([privatized_data_reduced, utility_cols_reduced, privacy_columns])\n",
    "nonprivatized_combined = pd.concat([nonprivatized_data_reduced, utility_cols_reduced, privacy_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the top five elements of both the combined dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  learning style   gpa  student semester         major previous courses  \\\n",
      "0   [0.51466924]  3.05              12.0  [0.57751447]      [0.5620219]   \n",
      "1    [0.4353882]  3.28               5.0  [0.57751447]      [0.7609531]   \n",
      "2    [0.5776786]  3.47               0.0  [0.53115463]    [0.017651517]   \n",
      "3   [0.53910905]  3.73              11.0  [0.57751447]     [0.28403044]   \n",
      "4    [0.5401469]  3.73               7.0  [0.57751447]      [0.7765268]   \n",
      "\n",
      "   course types course subjects subjects of interest  \\\n",
      "0   [0.1339442]     [0.5637837]         [0.51197636]   \n",
      "1  [0.56017077]     [0.4102107]         [0.37886214]   \n",
      "2    [0.631463]     [0.5462269]         [0.51299524]   \n",
      "3    [0.589439]      [0.642634]          [0.8003199]   \n",
      "4   [0.6601572]    [0.27176663]         [0.50578284]   \n",
      "\n",
      "  extracurricular activities career aspirations future topics  \\\n",
      "0               [0.58821774]                NaN           NaN   \n",
      "1                [0.4986311]                NaN           NaN   \n",
      "2               [0.17438826]                NaN           NaN   \n",
      "3                [0.6991976]                NaN           NaN   \n",
      "4                [0.5451047]                NaN           NaN   \n",
      "\n",
      "  ethnoracial group gender international status socioeconomic status  \n",
      "0               NaN    NaN                  NaN                  NaN  \n",
      "1               NaN    NaN                  NaN                  NaN  \n",
      "2               NaN    NaN                  NaN                  NaN  \n",
      "3               NaN    NaN                  NaN                  NaN  \n",
      "4               NaN    NaN                  NaN                  NaN  \n",
      "  learning style   gpa  student semester         major previous courses  \\\n",
      "0    [0.5376462]  3.84               4.0  [0.41955322]     [0.88638633]   \n",
      "1    [0.5376462]  3.26               5.0  [0.08774281]     [0.55915296]   \n",
      "2    [0.4410508]  3.61               8.0  [0.70278543]     [0.74052924]   \n",
      "3    [0.5345103]  2.28              12.0  [0.13271166]     [0.40154916]   \n",
      "4    [0.5352876]  2.93               9.0  [0.22174129]      [0.8778979]   \n",
      "\n",
      "   course types course subjects subjects of interest  \\\n",
      "0  [0.34658754]    [0.65389526]         [0.51253295]   \n",
      "1  [0.42354318]    [0.46442282]          [0.4339276]   \n",
      "2   [0.3093754]   [0.091108434]         [0.32733145]   \n",
      "3  [0.65194726]     [0.4375385]           [0.514679]   \n",
      "4  [0.44041365]    [0.67201746]         [0.36228055]   \n",
      "\n",
      "  extracurricular activities  \\\n",
      "0                [0.7454947]   \n",
      "1               [0.49763027]   \n",
      "2               [0.39969215]   \n",
      "3               [0.38828245]   \n",
      "4               [0.40747032]   \n",
      "\n",
      "                                  career aspirations            future topics  \\\n",
      "0                 [51, 49, 105, 87, 146, 27, 70, 85]   [55, 51, 145, 123, 50]   \n",
      "1      [70, 27, 23, 85, 87, 82, 52, 51, 105, 49, 24]   [108, 21, 30, 29, 128]   \n",
      "2      [94, 45, 130, 50, 112, 138, 114, 62, 101, 26]    [9, 37, 132, 191, 84]   \n",
      "3     [45, 4, 35, 79, 65, 108, 121, 12, 53, 54, 100]  [69, 114, 21, 134, 124]   \n",
      "4  [131, 101, 26, 61, 75, 24, 40, 20, 107, 73, 14...   [49, 48, 148, 191, 65]   \n",
      "\n",
      "  ethnoracial group gender international status socioeconomic status  \n",
      "0               NaN    NaN                  NaN                  NaN  \n",
      "1               NaN    NaN                  NaN                  NaN  \n",
      "2               NaN    NaN                  NaN                  NaN  \n",
      "3               NaN    NaN                  NaN                  NaN  \n",
      "4               NaN    NaN                  NaN                  NaN  \n"
     ]
    }
   ],
   "source": [
    "print(privatized_combined.head(n=5))\n",
    "print(nonprivatized_combined.head(n=5))\n",
    "# Change n to larger numbers to see more rows of the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our combined datasets we are ready to begin testing!\n",
    "\n",
    "***\n",
    "\n",
    "The reason for balancing the data privatization is to maximize the utility of the dataset while minimizing the privacy loss of the dataset. Perfectly private data would have no utility and vice versa.\n",
    "\n",
    "Since our private columns are distinct classes, the privacy loss will be measured with accuracy where we want a low accuracy to keep the data safe. Meanwhile, after the RNNs our utility columns are essentially continuous. Thus utility gain will be measured with error where we want a low error to keep the data useful.\n",
    "\n",
    "***\n",
    "\n",
    "Our first test for this is the classifier decision tree. Since it is a classifier we will be using it to test privacy loss for the private columns. Import the DTClassifier class from 'decision_tree_classifier'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calculating_tradeoffs.decision_tree_classifier.decision_tree_classifier import DTClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we instantiate 2 classes. One for the privatized data and one for the non privatized data. We will only run them for the 'Simple1' RNN model to keep things simple. Ba Dum Tss! Similarly we will only look at the 'ethnoracial group' target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_model = 'Simple1' # You can change it to 'GRU1' or 'LSTM1' if you like\n",
    "target = 'ethnoracial group' # You can change it to 'gender', 'international status', or 'socioeconomic status' if you like\n",
    "privatization_type = 'Basic_DP' # You can change it to 'NoPrivatization', 'Basic_DP_LLC', 'Uniform', 'Uniform_LLC', 'Shuffling', or 'Complete_Shuffling' if you like\n",
    "\n",
    "private_classifier = DTClassifier(privatization_type, RNN_model, target, privatized_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have instantiated the class we need to find the best model. We will use a metric called cost complexity pruning to decide how to prune our tree to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_model, ccp_alpha \u001b[38;5;241m=\u001b[39m \u001b[43mprivate_classifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_best_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmake_graphs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Leave this input to prevent the graphs from being produced\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(best_model)\n",
      "File \u001b[0;32m~/Documents/SummerREU2024/SummerResearch2024/calculating_tradeoffs/decision_tree_classifier/decision_tree_classifier.py:94\u001b[0m, in \u001b[0;36mDTClassifier.get_best_model\u001b[0;34m(self, make_graphs, return_model, return_ccp_alpha)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_best_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, make_graphs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_ccp_alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;66;03m# Split the data\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m# Generate the models with different ccp alphas\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     clf \u001b[38;5;241m=\u001b[39m DecisionTreeClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/SummerREU2024/SummerResearch2024/calculating_tradeoffs/decision_tree_classifier/decision_tree_classifier.py:81\u001b[0m, in \u001b[0;36mDTClassifier.split_data\u001b[0;34m(self, full_model)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# Change the lists into just the elements within them\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX\u001b[38;5;241m.\u001b[39mloc[:,column] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# Set up y post stratification\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstratified_data[[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget]]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf-gpu/lib/python3.11/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf-gpu/lib/python3.11/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf-gpu/lib/python3.11/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf-gpu/lib/python3.11/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf-gpu/lib/python3.11/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/SummerREU2024/SummerResearch2024/calculating_tradeoffs/decision_tree_classifier/decision_tree_classifier.py:81\u001b[0m, in \u001b[0;36mDTClassifier.split_data.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# Change the lists into just the elements within them\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX\u001b[38;5;241m.\u001b[39mloc[:,column] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX[column]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# Set up y post stratification\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstratified_data[[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget]]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "best_model, ccp_alpha = private_classifier.get_best_model(make_graphs=False) # Leave this input to prevent the graphs from being produced\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this best model look like? Let's print out the decision tree to see for ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "private_classifier.plotter(model=best_model, show_fig=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the best ccp alpha let us run that model and get the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "private_classifier.run_model(ccp_alpha=ccp_alpha, print_report=True, save_files=False, plot_files=False, get_shap=False) # Leave as is to prevent the graphs from being produced"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (SummerREU2024)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
