{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you are running this in a virtual environment! Otherwise you may cause problems to your main device. \n",
    "\n",
    "Look up how to create a virtual environment if you don't know how. Otherwise you can just run this in google colab. \n",
    "\n",
    "Then in your virtual environment run the following lines:\n",
    "\n",
    "***\n",
    "\n",
    "pip install jupyter\n",
    "\n",
    "pip install ipykernel\n",
    "\n",
    "python -m ipykernel install --user --name=myenv --display-name \"Python (myenv)\"\n",
    "\n",
    "pip install tensorflow\n",
    "\n",
    "pip install shap\n",
    "\n",
    "***\n",
    "\n",
    "The lines will install different packages and libraries that you need for this notebook. I may have forgotten some in which case you can likely just pip install \"name of package\" in the same format as above.\n",
    "\n",
    "Also, make sure to download all the files called here and every file in the 'data_files_for_data_construction' folder. Ideally you just download the whole github, but some of the CSV files are rather large.\n",
    "\n",
    "***\n",
    "\n",
    "Before we begin we have some standard python libraries to import that we will use throughout this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There was no existing dataset that contained the data needed for this project. Thus first we must generate a synthetic dataset. The dataset will be generated based on a variety of real data, mappings between datasets, and artificially generated lists. \n",
    "\n",
    "First we import the Data class which contains all the data needed to generate the synthetic dataset.\n",
    "\n",
    "Next we import the DataGenerator class for the CPU. Note that a version does exist that runs on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datafiles_for_data_construction.data import Data\n",
    "from data_generation.data_generation_CPU import DataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we instantiate the Data and DataGenerator classes. The Data class allows us to access all the data needed to generate the synthetic dataset and the DataGenerator class allows us to use the functions needed to generate the synthetic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data()\n",
    "data_generator = DataGenerator(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the data look like? Some of the data is a list of values. Some lists were generated synthetically, others were pulled from various sources. More information can be found in the README file. Here is a list of learning styles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Visual', 'Auditory', 'Read/Write', 'Kinesthetic']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.learning_style()[\"learning_style_list\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the data is a dictionary. Some dictionaries map different lists together while others map lists to demographic statistics on how common each item is. This dictionary maps the learning styles to the percentage of people that have said style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Visual': 27.27, 'Auditory': 23.56, 'Read/Write': 21.16, 'Kinesthetic': 28.01}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.learning_style()[\"learning_style\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the generate_synthetic_dataset function to create a dataset from all the data. This function has two inputs:\n",
    "- number of samples (an integer) which tell the function how many 'students' we want in our dataset\n",
    "- batch size (an integer) which tells the function how to split up the work to prevent overloading the computer.\n",
    "You can change the values if you want to generate more or less data. Be careful as higher values for number of samples will lead to a longer runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 100 # You can change these values if you want\n",
    "batch_size = 10 # Batch size should be about 1/10 of the number of samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we call the function. Use the time library to see how long the generator takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.857694864273071\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "synthetic_data = data_generator.generate_synthetic_dataset(num_samples, batch_size)\n",
    "end_time = time.time()\n",
    "runtime = end_time - start_time\n",
    "print(runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'generate_synthetic_dataset' outputs a pandas dataframe. Lets look at the top 5 elements of the dataframe. You can look back at the README file to get a better sense of what each column contains and how it was generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first name</th>\n",
       "      <th>last name</th>\n",
       "      <th>ethnoracial group</th>\n",
       "      <th>gender</th>\n",
       "      <th>international status</th>\n",
       "      <th>socioeconomic status</th>\n",
       "      <th>learning style</th>\n",
       "      <th>gpa</th>\n",
       "      <th>student semester</th>\n",
       "      <th>major</th>\n",
       "      <th>previous courses</th>\n",
       "      <th>course types</th>\n",
       "      <th>course subjects</th>\n",
       "      <th>subjects of interest</th>\n",
       "      <th>extracurricular activities</th>\n",
       "      <th>career aspirations</th>\n",
       "      <th>future topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nayleen</td>\n",
       "      <td>Liscombe</td>\n",
       "      <td>European American or white</td>\n",
       "      <td>Nonbinary</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>Lower-middle income</td>\n",
       "      <td>[Visual]</td>\n",
       "      <td>2.61</td>\n",
       "      <td>9</td>\n",
       "      <td>[Psychology]</td>\n",
       "      <td>[Data Science Discovery, College Physics: Mech...</td>\n",
       "      <td>[[Lecture, Discussion/Recitation, Laboratory],...</td>\n",
       "      <td>[ARCH, CS, CPSC, PHYS, ACCY, CHEM, HIST, RHET,...</td>\n",
       "      <td>[Psychology, Medicine, Education, Computer Sci...</td>\n",
       "      <td>[Pre-Pharmacy Club, Nursing Students Associati...</td>\n",
       "      <td>[Registered Nurse, Physician Assistant, Elemen...</td>\n",
       "      <td>[Psychology, Sociology, Cognitive Science, Neu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kindyl</td>\n",
       "      <td>Neale</td>\n",
       "      <td>European American or white</td>\n",
       "      <td>Female</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>In poverty</td>\n",
       "      <td>[Kinesthetic]</td>\n",
       "      <td>2.61</td>\n",
       "      <td>11</td>\n",
       "      <td>[Electrical Engineering]</td>\n",
       "      <td>[Introduction to Computer Science II, Engineer...</td>\n",
       "      <td>[[Laboratory, Laboratory-Discussion, Lecture],...</td>\n",
       "      <td>[TE, ASTR, CLE, CS, FR, PHYS, ATMS, EPOL, SPED...</td>\n",
       "      <td>[Engineering, Nuclear Engineering, Computer Sc...</td>\n",
       "      <td>[Computer Science Club, Robotics Club, Electri...</td>\n",
       "      <td>[Software Developer, Application and System So...</td>\n",
       "      <td>[Mechanical Engineering, Computer Engineering,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nala</td>\n",
       "      <td>Burgwin</td>\n",
       "      <td>African American or Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>Near poverty</td>\n",
       "      <td>[Read/Write, Visual]</td>\n",
       "      <td>3.26</td>\n",
       "      <td>2</td>\n",
       "      <td>[Engineering And Industrial Management, Nutrit...</td>\n",
       "      <td>[Introduction to Game Studies and Design, Data...</td>\n",
       "      <td>[[Online], [Lecture, Laboratory-Discussion], [...</td>\n",
       "      <td>[BCS, ATMS, DANC, HIST, GSD, SPAN, EPSY, CS]</td>\n",
       "      <td>[Nutrition, Food Science and Human Nutrition, ...</td>\n",
       "      <td>[Engineering Society, Culinary Arts Club, Indu...</td>\n",
       "      <td>[Sale Representative, Wholesale and Manufactur...</td>\n",
       "      <td>[Nutrition, Public Health, Biochemistry, Kines...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sahra</td>\n",
       "      <td>Pahr</td>\n",
       "      <td>European American or white</td>\n",
       "      <td>Male</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>Middle income</td>\n",
       "      <td>[Auditory]</td>\n",
       "      <td>2.84</td>\n",
       "      <td>5</td>\n",
       "      <td>[Composition And Rhetoric]</td>\n",
       "      <td>[Principles of Research, Molec and Cellular Ba...</td>\n",
       "      <td>[[Online], [Discussion/Recitation, Lecture-Dis...</td>\n",
       "      <td>[TAM, EDUC, KIN, CHEM, SE, GSD, RHET, CMN, CS,...</td>\n",
       "      <td>[Communications, Rhetoric and Composition, Lit...</td>\n",
       "      <td>[Fraternity Council, Men's Club, Broadcasting ...</td>\n",
       "      <td>[Secretary and Administrative Assistant, Broad...</td>\n",
       "      <td>[English, Journalism, Media and Cinema Studies...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gautham</td>\n",
       "      <td>Boitnott</td>\n",
       "      <td>African American or Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>Middle income</td>\n",
       "      <td>[Read/Write]</td>\n",
       "      <td>2.64</td>\n",
       "      <td>5</td>\n",
       "      <td>[Genetics]</td>\n",
       "      <td>[Intro to British Literature, MEP Mentoring, I...</td>\n",
       "      <td>[[Online], [Discussion/Recitation, Laboratory,...</td>\n",
       "      <td>[ENG, PHYS, CHEM, GSD, SPAN, ENGL, MATH, CS, L...</td>\n",
       "      <td>[Literature, Comparative World Literature, Eng...</td>\n",
       "      <td>[Journalism Club, Biology Club, Creative Writi...</td>\n",
       "      <td>[Writer and Author, Life, Physical, and Social...</td>\n",
       "      <td>[World Literatures, Molecular and Cellular Bio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  first name last name           ethnoracial group     gender  \\\n",
       "0    Nayleen  Liscombe  European American or white  Nonbinary   \n",
       "1     Kindyl     Neale  European American or white     Female   \n",
       "2       Nala   Burgwin   African American or Black     Female   \n",
       "3      Sahra      Pahr  European American or white       Male   \n",
       "4    Gautham  Boitnott   African American or Black     Female   \n",
       "\n",
       "  international status socioeconomic status        learning style   gpa  \\\n",
       "0             Domestic  Lower-middle income              [Visual]  2.61   \n",
       "1             Domestic           In poverty         [Kinesthetic]  2.61   \n",
       "2             Domestic         Near poverty  [Read/Write, Visual]  3.26   \n",
       "3             Domestic        Middle income            [Auditory]  2.84   \n",
       "4             Domestic        Middle income          [Read/Write]  2.64   \n",
       "\n",
       "   student semester                                              major  \\\n",
       "0                 9                                       [Psychology]   \n",
       "1                11                           [Electrical Engineering]   \n",
       "2                 2  [Engineering And Industrial Management, Nutrit...   \n",
       "3                 5                         [Composition And Rhetoric]   \n",
       "4                 5                                         [Genetics]   \n",
       "\n",
       "                                    previous courses  \\\n",
       "0  [Data Science Discovery, College Physics: Mech...   \n",
       "1  [Introduction to Computer Science II, Engineer...   \n",
       "2  [Introduction to Game Studies and Design, Data...   \n",
       "3  [Principles of Research, Molec and Cellular Ba...   \n",
       "4  [Intro to British Literature, MEP Mentoring, I...   \n",
       "\n",
       "                                        course types  \\\n",
       "0  [[Lecture, Discussion/Recitation, Laboratory],...   \n",
       "1  [[Laboratory, Laboratory-Discussion, Lecture],...   \n",
       "2  [[Online], [Lecture, Laboratory-Discussion], [...   \n",
       "3  [[Online], [Discussion/Recitation, Lecture-Dis...   \n",
       "4  [[Online], [Discussion/Recitation, Laboratory,...   \n",
       "\n",
       "                                     course subjects  \\\n",
       "0  [ARCH, CS, CPSC, PHYS, ACCY, CHEM, HIST, RHET,...   \n",
       "1  [TE, ASTR, CLE, CS, FR, PHYS, ATMS, EPOL, SPED...   \n",
       "2       [BCS, ATMS, DANC, HIST, GSD, SPAN, EPSY, CS]   \n",
       "3  [TAM, EDUC, KIN, CHEM, SE, GSD, RHET, CMN, CS,...   \n",
       "4  [ENG, PHYS, CHEM, GSD, SPAN, ENGL, MATH, CS, L...   \n",
       "\n",
       "                                subjects of interest  \\\n",
       "0  [Psychology, Medicine, Education, Computer Sci...   \n",
       "1  [Engineering, Nuclear Engineering, Computer Sc...   \n",
       "2  [Nutrition, Food Science and Human Nutrition, ...   \n",
       "3  [Communications, Rhetoric and Composition, Lit...   \n",
       "4  [Literature, Comparative World Literature, Eng...   \n",
       "\n",
       "                          extracurricular activities  \\\n",
       "0  [Pre-Pharmacy Club, Nursing Students Associati...   \n",
       "1  [Computer Science Club, Robotics Club, Electri...   \n",
       "2  [Engineering Society, Culinary Arts Club, Indu...   \n",
       "3  [Fraternity Council, Men's Club, Broadcasting ...   \n",
       "4  [Journalism Club, Biology Club, Creative Writi...   \n",
       "\n",
       "                                  career aspirations  \\\n",
       "0  [Registered Nurse, Physician Assistant, Elemen...   \n",
       "1  [Software Developer, Application and System So...   \n",
       "2  [Sale Representative, Wholesale and Manufactur...   \n",
       "3  [Secretary and Administrative Assistant, Broad...   \n",
       "4  [Writer and Author, Life, Physical, and Social...   \n",
       "\n",
       "                                       future topics  \n",
       "0  [Psychology, Sociology, Cognitive Science, Neu...  \n",
       "1  [Mechanical Engineering, Computer Engineering,...  \n",
       "2  [Nutrition, Public Health, Biochemistry, Kines...  \n",
       "3  [English, Journalism, Media and Cinema Studies...  \n",
       "4  [World Literatures, Molecular and Cellular Bio...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_data.head(n=5) # Change n to larger numbers to see more rows of the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we have columns that are lists and columns that are strings. Machine learning models need the input data to be numerical. Thus some data preprocessing is required.\n",
    "\n",
    "We import the Preprocessing class to do the preprocessing work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preprocessing.preprocessing import PreProcessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside the Preprocessing class there are two functions that do the main preprocessing work:\n",
    "- 'stringlist_to_binarylist': converts lists of strings into a binary list\n",
    "- 'string_list_to_numberedlist': converts lits of strings into a numbered list.\n",
    "\n",
    "Imagine the full options available are ['alice', 'bob', 'charlie']\n",
    "Thus for the entry ['alice', 'charlie'] we get:\n",
    "[1,0,1] for 'stringlist_to_binarylist'\n",
    "[0,2] for 'string_list_to_numberedlist'\n",
    "\n",
    "When we instantiate the class and call the 'preprocess_dataset' function both of the above functions will be called on certain columns. 'stringlist_to_binarylist' is called on 'learning styles' and 'string_list_to_numberedlist' is called on all the other lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "eval() arg 1 must be a string, bytes or code object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m preprocessor \u001b[38;5;241m=\u001b[39m PreProcessing(data)\n\u001b[1;32m      2\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 3\u001b[0m preprocessed_data \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43msynthetic_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      5\u001b[0m runtime \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/Documents/SummerREU2024/SummerResearch2024/data_preprocessing/preprocessing.py:199\u001b[0m, in \u001b[0;36mPreProcessing.preprocess_dataset\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m    196\u001b[0m     new_df[col] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstring_list_to_numberedlist(stringlist, new_df[col])\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m col \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcourse types\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;66;03m# Apply special function to fix the 'course types' column to be one nonrepeating list\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m     new_df[col] \u001b[38;5;241m=\u001b[39m \u001b[43mnew_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43meval\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfix_course_types)\n\u001b[1;32m    200\u001b[0m     stringlist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mcourse()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcourse_type_list\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    201\u001b[0m     new_df[col] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstring_list_to_numberedlist(stringlist, new_df[col])\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf-gpu/lib/python3.11/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf-gpu/lib/python3.11/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf-gpu/lib/python3.11/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf-gpu/lib/python3.11/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf-gpu/lib/python3.11/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: eval() arg 1 must be a string, bytes or code object"
     ]
    }
   ],
   "source": [
    "preprocessor = PreProcessing(data)\n",
    "start_time = time.time()\n",
    "preprocessed_data = preprocessor.preprocess_dataset(synthetic_data)\n",
    "end_time = time.time()\n",
    "runtime = end_time - start_time\n",
    "print(runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'preprocess_dataset' outputs a pandas dataframe. Lets look at the top 5 elements of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data.head(n=5) # Change n to larger numbers to see more rows of the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data has been preprocessed we must privatize the data to keep it safe.\n",
    "\n",
    "We import the Privatizer class to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_privatization.privatization import Privatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a variety of privatization methods you can try:\n",
    "- Basic Differential Privacy (laplace noise addition)\n",
    "- Uniform Noise Differential Privacy (uniform noise addition)\n",
    "- Shuffling\n",
    "Both Differential Privacy types can be done with or without list lengthening. This means the list columns like 'previous courses' could be lengthened according to the noise addition function. More details can be found in the README file. Let's try basic differential privacy with list lengthening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "privatization_type = 'basic differential privacy'\n",
    "# Other 'privatization_type' options: 'uniform', 'shuffle', 'full shuffle' (full shuffle shuffles all of the rows)\n",
    "privatizer = Privatizer(data, style=privatization_type, list_length=True)\n",
    "# Can set 'list_length' to false if you don't want to allow the list sizes to change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we call 'privatize_dataset'. Use the time library to see how long the privatizer takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "privatized_data = privatizer.privatize_dataset(preprocessed_data)\n",
    "end_time = time.time()\n",
    "runtime = end_time - start_time\n",
    "print(runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'preprocess_dataset' outputs a pandas dataframe. Lets look at the top 5 elements of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "privatized_data.head(n=5) # Change n to larger numbers to see more rows of the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have the problem of long lists. The 'previous courses list' can be over 30 elements long! Thus we call a new function from the Preprocessor class, 'create_RNN_models'. Three different recurrent neural network models are used to reduce the dimension of each list to 1 element. The three networks are: Simple, GRU (Gated Recurrent Units), and LSTM (Long Term Short Memory).\n",
    "\n",
    "Since 'create_RNN_models' takes in a dataframe, there is no need to create a new instance of the Preprocessor class. Thus we should call:\n",
    "- 'privatized_data': reduce dimensionality\n",
    "- 'preprocessed_data': give a null for comparison at the end\n",
    "- 'preprocessed_data' with 'utility=True': reduce dimensionality of the utility columns\n",
    "\n",
    "Let's also calculate and compare the runtimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "privatized_data_reduced = preprocessor.create_RNN_models(privatized_data)\n",
    "end_time = time.time()\n",
    "runtime = end_time - start_time\n",
    "print(f'Privatized data runtime: {runtime}')\n",
    "\n",
    "start_time = time.time()\n",
    "nonprivatized_data_reduced = preprocessor.create_RNN_models(preprocessed_data)\n",
    "end_time = time.time()\n",
    "runtime = end_time - start_time\n",
    "print(f'Nonprivatized data runtime: {runtime}')\n",
    "\n",
    "start_time = time.time()\n",
    "utility_cols_reduced = preprocessor.create_RNN_models(preprocessed_data, utility=True)\n",
    "end_time = time.time()\n",
    "runtime = end_time - start_time\n",
    "print(f'Utility columns runtime: {runtime}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'create_RNN_models' outputs a pandas dataframe. Lets look at the top 5 elements for each of the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(privatized_data_reduced.head(n=5))\n",
    "print(nonprivatized_data_reduced.head(n=5))\n",
    "print(utility_cols_reduced.head(n=5))\n",
    "# Change n to larger numbers to see more rows of the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason for balancing the data privatization is to maximize the utility of the dataset while minimizing the privacy loss of the dataset. Perfectly private data would have no utility and vice versa.\n",
    "\n",
    "Since our private columns are distinct classes, the privacy loss will be measured with accuracy where we want a low accuracy to keep the data safe. Meanwhile, after the RNNs our utility columns are essentially continuous. Thus utility gain will be measured with error where we want a low error to keep the data useful.\n",
    "\n",
    "Our first test for this is the classifier decision tree. Since it is a classifier we will be using it to test privacy loss for the private columns. Import the DTClassifier class from 'decision_tree_classifier'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'shap'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcalculating_tradeoffs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecision_tree_classifier\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecision_tree_classifier\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DTClassifier\n",
      "File \u001b[0;32m~/Documents/SummerREU2024/SummerResearch2024/calculating_tradeoffs/decision_tree_classifier/decision_tree_classifier.py:14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Add the SummerResearch2024 directory to sys.path\u001b[39;00m\n\u001b[1;32m     17\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(\u001b[38;5;18m__file__\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'shap'"
     ]
    }
   ],
   "source": [
    "from calculating_tradeoffs.decision_tree_classifier.decision_tree_classifier import DTClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we instantiate 2 classes. One for the privatized data and one for the non privatized data. We will only run them for the 'Simple1' RNN model to keep things simple. Ba Dum Tss! Similarly we will only look at the 'ethnoracial group' target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_model = 'Simple1' # You can change it to 'GRU1' or 'LSTM1' if you like\n",
    "target = 'ethnoracial group' # You can change it to 'gender', 'international status', or 'socioeconomic status' if you like\n",
    "\n",
    "private_classifier = DTClassifier(privatization_type, RNN_model, target)\n",
    "private_classifier.read_data(100)\n",
    "private_classifier.split_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have instantiated the class we need to find the best model. We will use a metric called cost complexity pruning to decide how to prune our tree to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model, ccp_alpha = private_classifier.get_best_model(make_graphs=False) # Leave this input to prevent the graphs from being produced\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this best model look like? Let's print out the decision tree to see for ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "private_classifier.plotter(model=best_model, show_fig=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the best ccp alpha let us run that model and get the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "private_classifier.run_model(ccp_alpha=ccp_alpha, print_report=True, save_files=False, plot_files=False, get_shap=False) # Leave as is to prevent the graphs from being produced"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (SummerREU2024)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
