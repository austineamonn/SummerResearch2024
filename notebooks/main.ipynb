{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction:\n",
    "\n",
    "This notebook is intended to show of the major functions of the IntelliShield package. No files produced in this notebook will be saved.\n",
    "\n",
    "Currently this model can be run on both Google Colab and Jupyter Notebook.If you want a more comprehensive way to explore the full functionality of the IntelliShield package try running the files in the 'scripts' folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter Notebook:\n",
    "\n",
    "The Jupyter Notebook will run the code locally. This is the best option if you plan to eventually use the full script functionality.\n",
    "\n",
    "How to set up the Jupyter Notebook:\n",
    "<ol>\n",
    " <li>Create a virtual environment to run the notebook in. The requirements can be found in the 'requirements.txt' file.</li>\n",
    " <li>Download the main.ipynb file.</li>\n",
    " <li>Download the IntelliShield Package.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this for Jupyter Notebook\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the path to the `src` directory\n",
    "src_path = os.path.abspath(os.path.join('..', 'src'))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Colab:\n",
    "\n",
    "Google Colab will run the code on the browser. This is the best option if you want to explore the use cases of the IntelliShield package or if you lack the space to locally host/store the notebook.\n",
    "\n",
    "How to set up Google Colab:\n",
    "<ol>\n",
    " <li>Open Google Colab and click 'Open Notebook'.</li>\n",
    " <li>Click the 'GitHub' line and type in 'austineamonn/SummerResearch2024'.</li>\n",
    " <li>Open the main.ipynb notebook.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this for Google Colab\n",
    "\n",
    "!git clone 'https://github.com/austineamonn/SummerResearch2024'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin we have some standard python libraries to import that we will use throughout this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation:\n",
    "\n",
    "There was no existing dataset that contained the data needed for this project. Thus first we must generate a synthetic dataset. The dataset will be generated based on a variety of real data, mappings between datasets, and artificially generated lists.\n",
    "\n",
    "***\n",
    "\n",
    "First we import the Data class which contains all the data needed to generate the synthetic dataset.\n",
    "\n",
    "Then we import the DataGenerator class for the CPU. Note that a version does exist that runs on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IntelliShield.data_generation.datafiles_for_data_construction.data import Data\n",
    "from IntelliShield.data_generation.data_generation_CPU import DataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we instantiate the Data and DataGenerator classes. The Data class allows us to access all the data needed to generate the synthetic dataset and the DataGenerator class allows us to use the functions needed to generate the synthetic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'first_names.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m data \u001b[38;5;241m=\u001b[39m Data()\n\u001b[0;32m----> 2\u001b[0m data_generator \u001b[38;5;241m=\u001b[39m \u001b[43mDataGenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/SummerREU2024/SummerResearch2024/src/IntelliShield/data_generation/data_generation_CPU.py:23\u001b[0m, in \u001b[0;36mDataGenerator.__init__\u001b[0;34m(self, data, config)\u001b[0m\n\u001b[1;32m     20\u001b[0m     logging\u001b[38;5;241m.\u001b[39mbasicConfig(level\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mINFO\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%(asctime)s\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m%(levelname)s\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m%(message)s\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# First Names\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m first_names_data \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfirst_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfirst_names \u001b[38;5;241m=\u001b[39m first_names_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Last Names\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/SummerREU2024/SummerResearch2024/src/IntelliShield/data_generation/datafiles_for_data_construction/data.py:15\u001b[0m, in \u001b[0;36mData.first_name\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfirst_name\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# Reading from a JSON file\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfirst_names.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     16\u001b[0m         first_names \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     18\u001b[0m     first_name \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst_name\u001b[39m\u001b[38;5;124m'\u001b[39m: first_names\n\u001b[1;32m     20\u001b[0m     }\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'first_names.json'"
     ]
    }
   ],
   "source": [
    "data = Data()\n",
    "data_generator = DataGenerator(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the data look like? Some of the data is a list of values. Some lists were generated synthetically, others were pulled from various sources. More information can be found in the README file. Here is a list of learning styles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.learning_style()[\"learning_style_list\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the data is a dictionary. Some dictionaries map different lists together while others map lists to demographic statistics on how common each item is. This dictionary maps the learning styles to the percentage of people that have said style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.learning_style()[\"learning_style\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the generate_synthetic_dataset function to create a dataset from all the data. This function has two inputs:\n",
    "- number of samples (an integer) which tell the function how many 'students' we want in our dataset\n",
    "- batch size (an integer) which tells the function how to split up the work to prevent overloading the computer.\n",
    "You can change the values if you want to generate more or less data. Be careful as higher values for number of samples will lead to a longer runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 100 # You can change these values if you want\n",
    "batch_size = 10 # Batch size should be about 1/10 of the number of samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we call the function. Use the time library to see how long the generator takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "synthetic_data = data_generator.generate_synthetic_dataset(num_samples, batch_size)\n",
    "end_time = time.time()\n",
    "runtime = end_time - start_time\n",
    "print(runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'generate_synthetic_dataset' outputs a pandas dataframe. Let's examine the properties of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_data.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the top 5 elements of the dataframe. You can look back at the README file to get a better sense of what each column contains and how it was generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_data.head(n=5) # Change n to larger numbers to see more rows of the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we have columns that are lists and columns that are strings. Machine learning models need the input data to be numerical. Thus some data preprocessing is required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing and Privatization:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the Preprocessing class to do the preprocessing work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Tradeoffs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IntelliShield.tradeoffs import ISDecisionTreeClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of RNN models to run\n",
    "RNN_model_list = ['GRU1', 'LSTM1', 'Simple1']\n",
    "\n",
    "# List of Privatization Types to run\n",
    "privatization_types = ['NoPrivatization', 'Basic_DP', 'Basic_DP_LLC', 'Uniform', 'Uniform_LLC', 'Shuffling', 'Complete_Shuffling']\n",
    "\n",
    "# List of targets for the model \n",
    "targets = ['future topic 1', 'future topic 2', 'future topic 3', 'future topic 4', 'future topic 5']\n",
    "\n",
    "# Get the runtime values for the function\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "\n",
    "for privatization_type in privatization_types:\n",
    "    logging.info(f\"Starting {privatization_type}\")\n",
    "    for RNN_model in RNN_model_list:\n",
    "        logging.info(f\"Starting {RNN_model}\")\n",
    "\n",
    "        # Data Path\n",
    "        data_path = f'{data_folder}/{privatization_type}/{RNN_model}_alt_future_topics.csv'\n",
    "\n",
    "        # Data\n",
    "        data = pd.read_csv(data_path, converters={\n",
    "            'learning style': literal_eval,\n",
    "            'major': literal_eval,\n",
    "            'previous courses': literal_eval,\n",
    "            'course types': literal_eval,\n",
    "            'course subjects': literal_eval,\n",
    "            'subjects of interest': literal_eval,\n",
    "            'extracurricular activities': literal_eval,\n",
    "            'career aspirations': literal_eval,\n",
    "            'future topics': literal_eval\n",
    "        })\n",
    "\n",
    "        for target in targets:\n",
    "            logging.info(f\"Starting {target}\")\n",
    "\n",
    "            target_name = target.replace(' ', '_')\n",
    "\n",
    "            target_path = f'{output_path}/outputs/{privatization_type}/{RNN_model}/{target_name}'\n",
    "\n",
    "            # Initiate regressifier\n",
    "            regressifier = ISDecisionTreeRegressification(privatization_type, RNN_model, target, data=data, output_path=target_path)\n",
    "            pipeline(regressifier, full_run=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(Model, ISDecisionTreeClassification) or isinstance(Model, ISDecisionTreeRegressification) or isinstance(Model, ISDecisionTreeRegression):\n",
    "                get_best_model(Model)\n",
    "            \n",
    "# Run the main model\n",
    "run_model(Model)\n",
    "\n",
    "if isinstance(Model, ISDecisionTreeClassification) or isinstance(Model, ISDecisionTreeRegressification) or isinstance(Model, ISDecisionTreeRegression) or isinstance(Model, ISRandomForestClassification) or isinstance(Model, ISRandomForestRegressification) or isinstance(Model, ISRandomForestRegression):\n",
    "    tree_plotter(Model, save_fig=True)\n",
    "\n",
    "if isinstance(Model, ISDecisionTreeClassification) or isinstance(Model, ISDecisionTreeRegressification) or isinstance(Model, ISLogisticRegression) or isinstance(Model, ISLinearRegressification) or isinstance(Model, ISRandomForestClassification) or isinstance(Model, ISRandomForestRegressification):\n",
    "    confusion_matrix_plotter(Model, save_fig=True)\n",
    "\n",
    "if isinstance(Model, ISLinearRegression):\n",
    "    linear_regression_plotter(Model)\n",
    "\n",
    "# Get the SHAP values\n",
    "calculate_shap_values(Model)\n",
    "load_shap_values(Model, f'{Model.output_path}/shap_values.npy')\n",
    "plot_shap_values(Model)\n",
    "\n",
    "# Get feature importance\n",
    "get_feature_importance(Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Models:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (SummerREU2024)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
